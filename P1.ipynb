{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project: **Finding Lane Lines on the Road** \n",
    "\n",
    "The goal of this project is to identify lane lines on the road from a set of images and videos.\n",
    "\n",
    "The following image processing techniques are applied (OpenCV implementations):\n",
    "- Gaussian Blurring\n",
    "- Canny edge detection\n",
    "- Region masking\n",
    "- Hough transform\n",
    "\n",
    "Starter code can be found at [https://github.com/udacity/CarND-LaneLines-P1](https://github.com/udacity/CarND-LaneLines-P1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "# inline plots\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in a Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 12.5)\n",
    "\n",
    "#reading in an image\n",
    "image = mpimg.imread('test_images/solidWhiteRight.jpg')\n",
    "\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimensions:', image.shape)\n",
    "plt.imshow(image)  # if you wanted to show a single color channel image called 'gray', for example, call as plt.imshow(gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    Draws `lines` with `color` and `thickness` onto 'img'.    \n",
    "    Lines are drawn in-place (mutates the image).\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "            \n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane-finding Pipeline on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify directory names.\n",
    "in_dir = 'test_images/'\n",
    "subplots_dir = 'test_images_intermediate/'  # dir for intermediate images\n",
    "out_dir = 'test_images_out_detect/'\n",
    "\n",
    "# Create output directories if needed.\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(subplots_dir):\n",
    "    os.makedirs(subplots_dir)\n",
    "\n",
    "# Process each file in input directory.\n",
    "for img_filename in os.listdir(in_dir):\n",
    "\n",
    "    # Set up a subplot for keeping intermediate images.\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Lane Detection on ' + img_filename)\n",
    "    \n",
    "    # Read in image.\n",
    "    img = mpimg.imread(in_dir + img_filename)\n",
    "    a = fig.add_subplot(4,2,1)\n",
    "    plt.imshow(img)\n",
    "    a.set_title('Original')\n",
    "    \n",
    "    # Convert image to grayscale.\n",
    "    gray_img = grayscale(img)\n",
    "    a = fig.add_subplot(4,2,2)\n",
    "    plt.imshow(gray_img, cmap='gray')\n",
    "    a.set_title('Grayscale')\n",
    "    \n",
    "    # Apply Gaussian blurring.\n",
    "    for i in range(0,3):\n",
    "        kernel_size = 5\n",
    "        gs_gray_img = gaussian_blur(gray_img, 5)\n",
    "    a = fig.add_subplot(4,2,3)\n",
    "    plt.imshow(gs_gray_img, cmap='gray')\n",
    "    a.set_title('Gaussian blurred')\n",
    "\n",
    "    # Perform Canny edge detection.\n",
    "    lower_thresh = 50\n",
    "    upper_thresh = 150\n",
    "    canny_img = canny(gs_gray_img, lower_thresh, upper_thresh)\n",
    "    a = fig.add_subplot(4,2,4)\n",
    "    plt.imshow(canny_img, cmap='gray')\n",
    "    a.set_title('Canny edge')\n",
    "\n",
    "    # Apply ROI masking to edge image.\n",
    "    h_offset = 20\n",
    "    v_offset = 50\n",
    "    l_base = 0\n",
    "    r_base = 960\n",
    "    left_bottom = [l_base, img.shape[0]]\n",
    "    left_top = [img.shape[1]/2 - h_offset, img.shape[0]/2 + v_offset]\n",
    "    right_top =  [img.shape[1]/2 + h_offset, img.shape[0]/2 + v_offset]\n",
    "    right_bottom = [r_base, img.shape[0]]\n",
    "    \n",
    "    # https://stackoverflow.com/questions/17241830/opencv-polylines-function-in-python-throws-exception/18817152#18817152)\n",
    "    # ^ regarding input to cv2.fillpoly\n",
    "    roi = [np.array([left_bottom, left_top, right_top, right_bottom], np.int32)]\n",
    "    roi_canny_img = region_of_interest(canny_img, roi)\n",
    "    a = fig.add_subplot(4,2,5)\n",
    "    plt.imshow(roi_canny_img, cmap='gray')\n",
    "    a.set_title('Edges after ROI mask')\n",
    "\n",
    "    # Obtain Hough transform lines within ROI.\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 5\n",
    "    min_line_len = 10\n",
    "    max_line_gap = 5\n",
    "    roi_hough_img = hough_lines(roi_canny_img, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    a = fig.add_subplot(4,2,6)\n",
    "    plt.imshow(roi_hough_img)\n",
    "    a.set_title('Hough lines')\n",
    "    \n",
    "    # Overlay detected lines on top of original image.\n",
    "    ann_img = weighted_img(roi_hough_img, img, 1, 2, 0)\n",
    "    a = fig.add_subplot(4,2,7)\n",
    "    plt.imshow(ann_img)\n",
    "    a.set_title('Output')\n",
    "    \n",
    "    # Save intermediate and output images.\n",
    "    plt.savefig(subplots_dir + 'intermediate_' + img_filename)\n",
    "    mpimg.imsave(out_dir + 'annotated_' + img_filename, ann_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improved 'draw_lines' function - extrapolates lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extrapolate_lines(img, lines, roi, m_thresh, color=[255, 0, 0], thickness=2):\n",
    "    '''\n",
    "    This is the improved 'draw_lines' function that extrapolates the lane, \n",
    "    based on provided hough_lines, slope threshold, and ROI.\n",
    "    '''\n",
    "    left_lane_points = []\n",
    "    right_lane_points = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # Get line endpoints and calculate slope.\n",
    "        x0, y0, x1, y1 = line[0]\n",
    "        m = -(y1-y0) / (x1-x0)\n",
    "        \n",
    "        # Reject lines with slope not representative of a lane line.\n",
    "        if abs(m) < m_thresh:\n",
    "            continue\n",
    "            \n",
    "        # Classify line endpoints as part of left lane or right lane.\n",
    "        if m > 0:\n",
    "            left_lane_points.append([x0, y0])\n",
    "            left_lane_points.append([x1, y1])\n",
    "        else:\n",
    "            right_lane_points.append([x0, y0])\n",
    "            right_lane_points.append([x1, y1])\n",
    "\n",
    "    # Use np.polyfit to find the line of best fit for the LEFT lane.\n",
    "    if (len(left_lane_points)) > 0:\n",
    "        left_lane_points = np.array(left_lane_points)\n",
    "        m, b = np.polyfit(left_lane_points[:,0], left_lane_points[:,1], 1)\n",
    "        bot_y = int(roi[0][0,1])\n",
    "        bot_x = int((bot_y - b) / m)\n",
    "        top_y = int(roi[0][1,1])\n",
    "        top_x = int((top_y - b) / m)\n",
    "        cv2.line(img, (bot_x,bot_y), (top_x,top_y), color, thickness)\n",
    "                 \n",
    "    # Use np.polyfit to find the line of best fit for the RIGHT lane.\n",
    "    if len(right_lane_points) > 0:\n",
    "        right_lane_points = np.array(right_lane_points)\n",
    "        m, b = np.polyfit(right_lane_points[:,0], right_lane_points[:,1], 1)\n",
    "        bot_y = int(roi[0][3,1])\n",
    "        bot_x = int((bot_y - b) / m)\n",
    "        top_y = int(roi[0][2,1])\n",
    "        top_x = int((top_y - b) / m)\n",
    "        cv2.line(img, (bot_x,bot_y), (top_x,top_y), color, thickness)\n",
    "\n",
    "    return [left_lane_points, right_lane_points]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Extrapolation on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "    '''\n",
    "    Outputs a color image (3 channel) for processing video below\n",
    "    '''\n",
    "    \n",
    "    # Convert input image to grayscale.\n",
    "    gray_img = grayscale(img)\n",
    "    \n",
    "    # Apply multiple Gaussian blurs .\n",
    "    gs_gray_img = gray_img\n",
    "    for i in range(0,1):\n",
    "        kernel_size = 5\n",
    "        gs_gray_img = gaussian_blur(gray_img, 5)\n",
    "    \n",
    "    # Perform Canny edge detection.\n",
    "    lower_thresh = 50\n",
    "    upper_thresh = 150\n",
    "    canny_img = canny(gs_gray_img, lower_thresh, upper_thresh)\n",
    "      \n",
    "    # Apply ROI masking to edge image.\n",
    "    h_offset = 20\n",
    "    v_offset = 50\n",
    "    l_base = 0\n",
    "    r_base = 960\n",
    "    left_bottom = [l_base, img.shape[0]]\n",
    "    left_top = [img.shape[1]/2 - h_offset, img.shape[0]/2 + v_offset]\n",
    "    right_top =  [img.shape[1]/2 + h_offset, img.shape[0]/2 + v_offset]\n",
    "    right_bottom = [r_base, img.shape[0]]\n",
    "    \n",
    "    roi = [np.array([left_bottom, left_top, right_top, right_bottom], np.int32)]\n",
    "    roi_canny_img = region_of_interest(canny_img, roi)\n",
    "    \n",
    "    # Obtain Hough transform lines within ROI.\n",
    "    rho = 1\n",
    "    theta = np.pi/180\n",
    "    threshold = 20\n",
    "    min_line_len = 20\n",
    "    max_line_gap = 10\n",
    "    roi_hough_img = hough_lines(roi_canny_img, rho, theta, threshold, min_line_len, max_line_gap)\n",
    "    h_lines = cv2.HoughLinesP(roi_canny_img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "\n",
    "    m_thresh = 0.4\n",
    "    line_thickness = 10\n",
    "    roi_lanes_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)  # empty image\n",
    "    roi_lanes = extrapolate_lines(roi_lanes_img, h_lines, roi, m_thresh, (255,0,0), line_thickness)\n",
    "    #roi_lanes = extrapolate_lines(roi_lanes_img, h_lines, roi, m_thresh, (0,255,0), line_thickness)\n",
    "    \n",
    "    # Overlay detected lines on top of original image.\n",
    "    ann_img = weighted_img(roi_lanes_img, img, 1, 2, 0)    \n",
    "    return ann_img\n",
    "    #return roi_hough_img\n",
    "    \n",
    "    #ann_img = weighted_img(roi_lanes_img, roi_hough_img, 1, 2, 0)    \n",
    "    #return ann_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify directory names.\n",
    "in_dir = 'test_images/'\n",
    "out_dir = 'test_images_out_extrapolate/'\n",
    "\n",
    "# Create output directories if needed.\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "if not os.path.exists(subplots_dir):\n",
    "    os.makedirs(subplots_dir)\n",
    "\n",
    "# Process each file in input directory.\n",
    "for img_filename in os.listdir(in_dir):\n",
    "\n",
    "    # Read in image.\n",
    "    img = mpimg.imread(in_dir + img_filename)\n",
    "\n",
    "    # Delegate to pipeline.\n",
    "    ann_img = process_image(img)\n",
    "    \n",
    "    # Save intermediate and output images.\n",
    "    mpimg.imsave(out_dir + 'annotated_' + img_filename, ann_img)\n",
    "    plt.imshow(ann_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lane Detection Pipeline on Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video 1: 'solidWhiteRight.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "input_dir = 'test_videos/'\n",
    "output_dir = 'test_videos_output/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'solidWhiteRight.mp4'\n",
    "\n",
    "#clip1 = VideoFileClip(input_dir + filename).subclip(0,5)\n",
    "clip1 = VideoFileClip(input_dir + filename)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output_dir + filename, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_dir + filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video 2: 'solidYellowLeft.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'solidYellowLeft.mp4'\n",
    "\n",
    "#clip2 = VideoFileClip(input_dir + filename).subclip(0,5)\n",
    "clip2 = VideoFileClip(input_dir + filename)\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(output_dir + filename, audio=False)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_dir + filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## [Todo] Optional Challenge\n",
    "\n",
    "Try your lane finding pipeline on the video below.  Does it still work?  Can you figure out a way to make it more robust?  If you're up for the challenge, modify your pipeline so it works with this video and submit it along with the rest of your project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "challenge_output = 'test_videos_output/challenge.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip3 = VideoFileClip('test_videos/challenge.mp4').subclip(0,5)\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "challenge_clip = clip3.fl_image(process_image)\n",
    "%time challenge_clip.write_videofile(challenge_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(challenge_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
